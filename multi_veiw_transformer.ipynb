{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "multi_veiw_transformer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOhdJqsba4hFaJ0QIGrS1hx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/the-chosen-wan/deepfake-detection/blob/main/multi_veiw_transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jMJ2hqG7aUX"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Model\n",
        "import os\n",
        "import glob"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3S8odEEcSnlA"
      },
      "source": [
        "pow_list=[1,2,4,8,16,32,64,128,256,512,1024,2048]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35JD-e2a9S-w",
        "outputId": "dae71ebc-2953-4527-b5f4-f60a3136e8b6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ka8HtLp48v_K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "outputId": "b17e2961-ac47-4b1b-8c58-571edffcb513"
      },
      "source": [
        "\n",
        "def Meso4():\n",
        "        x = layers.Input(shape = (256,256, 3))\n",
        "        \n",
        "        x1 = layers.Conv2D(8, (3, 3), padding='same', activation = 'relu')(x)\n",
        "        x1 = layers.BatchNormalization()(x1)\n",
        "        x1 = layers.MaxPooling2D(pool_size=(2, 2), padding='same')(x1)\n",
        "        \n",
        "        x2 = layers.Conv2D(8, (5, 5), padding='same', activation = 'relu')(x1)\n",
        "        x2 = layers.BatchNormalization()(x2)\n",
        "        x2 = layers.MaxPooling2D(pool_size=(2, 2), padding='same')(x2)\n",
        "        \n",
        "        x3 = layers.Conv2D(16, (5, 5), padding='same', activation = 'relu')(x2)\n",
        "        x3 = layers.BatchNormalization()(x3)\n",
        "        x3 = layers.MaxPooling2D(pool_size=(2, 2), padding='same')(x3)\n",
        "        \n",
        "        x4 = layers.Conv2D(16, (5, 5), padding='same', activation = 'relu')(x3)\n",
        "        x4 = layers.BatchNormalization()(x4)\n",
        "        x4 = layers.MaxPooling2D(pool_size=(4, 4), padding='same')(x4)\n",
        "        \n",
        "        y = layers.Flatten()(x4)\n",
        "        y = layers.Dropout(0.5)(y)\n",
        "        y = layers.Dense(16)(y)\n",
        "        y = layers.LeakyReLU(alpha=0.1)(y)\n",
        "        y = layers.Dropout(0.5)(y)\n",
        "        y = layers.Dense(1, activation = 'sigmoid')(y)\n",
        "\n",
        "        return Model(inputs = x, outputs = y)\n",
        "meso  = Meso4()\n",
        "meso.load_weights('/content/drive/My Drive/weights/Meso4_F2F.h5')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-6278ca4e3492>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mmeso\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mMeso4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mmeso\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/weights/Meso4_F2F.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, **kwds)\u001b[0m\n\u001b[1;32m    425\u001b[0m                                fapl, fcpl=make_fcpl(track_order=track_order, fs_strategy=fs_strategy,\n\u001b[1;32m    426\u001b[0m                                fs_persist=fs_persist, fs_threshold=fs_threshold),\n\u001b[0;32m--> 427\u001b[0;31m                                swmr=swmr)\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = '/content/drive/My Drive/weights/Meso4_F2F.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOroEWIO9gZL"
      },
      "source": [
        "meso.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTC9LmVMbaIJ"
      },
      "source": [
        "class mlp(layers.Layer):\n",
        "  def __init__(self,units,drop):\n",
        "    super(mlp,self).__init__()\n",
        "    self.units = units\n",
        "    self.drop = drop\n",
        "\n",
        "    self.dense=[]\n",
        "    self.drop_layer=layers.Dropout(self.drop)\n",
        "    for unit in units:\n",
        "      self.dense.append(layers.Dense(unit,activation='relu'))\n",
        "  \n",
        "  def get_config(self):\n",
        "    config = super(mlp,self).get_config()\n",
        "    config.update({\"drop\":self.drop,\"units\":self.units})\n",
        "    return config\n",
        "  \n",
        "  def call(self,x):\n",
        "\n",
        "    for i in range(len(self.units)):\n",
        "      x = self.dense[i](x)\n",
        "      x = self.drop_layer(x)\n",
        "    return x\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slIZMt8UTZ6r"
      },
      "source": [
        "class transformer(layers.Layer):\n",
        "  def __init__(self,transformer_layers,num_heads):\n",
        "    super(transformer,self).__init__()\n",
        "    self.layers = transformer_layers\n",
        "    self.heads = num_heads\n",
        "  \n",
        "  def get_config(self):\n",
        "     config = super(transformer, self).get_config()\n",
        "     config.update({\"transformer_layers\": self.layers,\"num_heads\":self.heads})\n",
        "     return config\n",
        "  \n",
        "  def build(self,input_shape):\n",
        "    self.embed_dim = input_shape[2]\n",
        "    self.units = [2*self.embed_dim,self.embed_dim]\n",
        "    self.dense=[]\n",
        "    self.layer_norm1=[]\n",
        "    self.layer_norm2=[]\n",
        "    self.mha=[]\n",
        "    for i in range(self.layers):\n",
        "      self.dense.append(mlp(self.units,0.2))\n",
        "      self.layer_norm1.append(layers.LayerNormalization(epsilon=1e-6))\n",
        "      self.layer_norm2.append(layers.LayerNormalization(epsilon=1e-6))\n",
        "      self.mha.append(layers.MultiHeadAttention(num_heads=self.heads,key_dim=self.embed_dim))\n",
        "    \n",
        "  def call(self,x):\n",
        "\n",
        "    for i in range(self.layers):\n",
        "      x1 = self.layer_norm1[i](x)\n",
        "      x1 = self.mha[i](x1,x1)\n",
        "      x2 = layers.Add()([x,x1])\n",
        "      x3 = self.layer_norm2[i](x2)\n",
        "      x3 = self.dense[i](x3)\n",
        "      x = layers.Add()([x3,x2]) \n",
        "        \n",
        "    return x"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yd-QMfTLMoy"
      },
      "source": [
        "class Patch(layers.Layer):\n",
        "    def __init__(self,patch_size):\n",
        "        super(Patch,self).__init__()\n",
        "        self.patch_size=patch_size\n",
        "    \n",
        "    def get_config(self):\n",
        "        config = super(Patch, self).get_config()\n",
        "        config.update({\"patch_size\": self.patch_size})\n",
        "        return config\n",
        "\n",
        "    def call(self,patch):\n",
        "        batch = tf.shape(patch)[0]\n",
        "        patches = tf.image.extract_patches(\n",
        "                  images = patch,\n",
        "                  sizes = [1,self.patch_size,self.patch_size,1],\n",
        "                  strides = [1,self.patch_size,self.patch_size,1],\n",
        "                  rates = [1,1,1,1],\n",
        "                  padding = 'VALID')\n",
        "        dims = patches.shape[-1]\n",
        "        patches = tf.reshape(patches,[batch,-1,dims])\n",
        "        return patches"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzqiDaFUGv7A"
      },
      "source": [
        "class inverse_patch(layers.Layer):\n",
        "  def __init__(self,target_shape,patch_size):\n",
        "    super(inverse_patch,self).__init__()\n",
        "    self.H = target_shape[0]\n",
        "    self.B = target_shape[1]\n",
        "    self.C = target_shape[2]\n",
        "    self.patch_size = patch_size\n",
        "  \n",
        "  def call(self,x):\n",
        "    batch_size = tf.shape(x)[0]\n",
        "    num_patches = tf.shape(x)[1]\n",
        "    pad = [[0,0],[0,0]]\n",
        "    p = self.patch_size\n",
        "    h = self.H\n",
        "    patches = tf.reshape(x,[batch_size,num_patches,p,p,self.C])\n",
        "    patches_proc = tf.reshape(patches,[batch_size,h//p,h//p,p*p,self.C])\n",
        "    patches_proc = tf.split(patches_proc,p*p,3)\n",
        "    patches_proc = tf.stack(patches_proc,axis=0)\n",
        "    patches_proc = tf.reshape(patches_proc,[p*p*batch_size,h//p,h//p,self.C])\n",
        "    reconstructed = tf.compat.v1.batch_to_space_nd(patches_proc,[p, p],pad)\n",
        "    return reconstructed"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JiqCrLbJ7nQu"
      },
      "source": [
        "class encoding(layers.Layer):\n",
        "    def __init__(self,num_patches,projection_dim):\n",
        "        super(encoding,self).__init__()\n",
        "        self.num = num_patches\n",
        "        self.projection_dim = projection_dim\n",
        "        self.dense = layers.Dense(self.projection_dim)\n",
        "        self.embed = layers.Embedding(input_dim = num_patches , output_dim = self.projection_dim)\n",
        "    \n",
        "    def get_config(self):\n",
        "        config = super(encoding, self).get_config()\n",
        "        config.update({\"num_patches\": self.num,\"projection_dim\":self.projection_dim})\n",
        "        return config\n",
        "    \n",
        "    def call(self,patch):\n",
        "        pos = tf.range(start = 0,limit = self.num , delta =1)\n",
        "        return self.dense(patch) + self.embed(pos)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQ6crSg47vR2"
      },
      "source": [
        "class simple_attention(layers.Layer):\n",
        "  def __init__(self,projection_dim,pow_list):\n",
        "\n",
        "    super(simple_attention,self).__init__()\n",
        "    self.projection_dim=projection_dim\n",
        "    self.pow_list = pow_list\n",
        "  \n",
        "  def get_config(self):\n",
        "    config = super(simple_attention,self).get_config()\n",
        "    config.update({\"projection_dim\":self.projection_dim,\"pow_list\":self.pow_list})\n",
        "    return config\n",
        "    \n",
        "  def build(self,input_shape):\n",
        "    H = input_shape[1]\n",
        "    B = input_shape[2]\n",
        "    C = input_shape[-1]\n",
        "    res1 = tf.cast(tf.math.ceil(np.log2(H)),dtype='int32')\n",
        "    res = self.pow_list[res1]\n",
        "    self.patch_size=(res//8)\n",
        "    self.patch_encoder = Patch(self.patch_size)\n",
        "    p = C*(self.patch_size)**2\n",
        "    norm = tf.math.sqrt(tf.cast(p,dtype='float32'))\n",
        "\n",
        "\n",
        "    self.num_patches = ((res)//self.patch_size)**2\n",
        "    #self.resize = layers.Resizing(res,res)\n",
        "    self.conv = layers.Conv2D(C,kernel_size=1)\n",
        "    #self.key_conv = layers.Conv2D(C,kernel_size=1)\n",
        "    #self.value_conv = layers.Conv2D(C,kernel_size=1)\n",
        "    self.embed = encoding(self.num_patches,self.projection_dim)\n",
        "    #self.reshape = inverse_patch((8,8,32),self.patch_size)\n",
        "    self.sa = transformer(12,4)\n",
        "    #self.sa = layers.Attention()\n",
        "    self.normalizer = layers.Lambda(lambda x: x/norm)\n",
        "  \n",
        "  def call(self,x):\n",
        "    #x = self.resize(x1)\n",
        "    query_block = self.conv(x)\n",
        "    #key_block = self.key_conv(x)\n",
        "    #value_block = self.value_conv(x)\n",
        "\n",
        "    query_block = self.patch_encoder(query_block)\n",
        "    query_block = self.embed(query_block)\n",
        "\n",
        "    #key_block = self.patch_encoder(key_block)\n",
        "    #key_block = self.embed(key_block)\n",
        "\n",
        "    #value_block = self.patch_encoder(value_block)\n",
        "    #value_block = self.embed(value_block)\n",
        "\n",
        "    out = self.sa(query_block)\n",
        "    #out = self.sa([query_block,value_block,key_block])\n",
        "    out = self.normalizer(out)\n",
        "    #out = self.reshape(out)\n",
        "    return out"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMl7Ok_t7yVP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10396914-2ebc-4158-870b-6ba1fca09d78"
      },
      "source": [
        "backbone_cnn = meso#tf.keras.applications.Xception(include_top = False,weights='imagenet',input_shape=(256,256,3))\n",
        "layer_list = [2,5,8,11,12]#[0,4,12,22,32,-10]\n",
        "r=tf.cast(tf.math.ceil(np.log2(22)),dtype='int32')\n",
        "pow_list[r]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "MycLDqQYenja",
        "outputId": "948b241a-cfb8-4b57-82b7-2cdcd71237f1"
      },
      "source": [
        "backbone_cnn.layers[22].output"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-fe1611860f86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbackbone_cnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m22\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1D9mbzLo8gdX"
      },
      "source": [
        "def multi_veiw_attention(embedding_dim):\n",
        "  heads = []\n",
        "  l = len(layer_list)\n",
        "  for i in range(l):\n",
        "    heads.append(simple_attention(embedding_dim,pow_list))\n",
        "\n",
        "  out = heads[0]((backbone_cnn.layers[layer_list[0]].output))\n",
        "  out = tf.expand_dims(out,axis=-1)\n",
        "\n",
        "  for i in range(1,l):\n",
        "    t = heads[i](backbone_cnn.layers[layer_list[i]].output)\n",
        "    t = tf.expand_dims(t,axis=-1)\n",
        "    out = layers.Concatenate(axis=-1)([out,t])\n",
        "  \n",
        "  out = tf.keras.backend.mean(out,axis=-1)\n",
        "  out = layers.Flatten()(out)\n",
        "  out = mlp([1024,512],0.5)(out)\n",
        "  out = layers.Dense(2,activation='softmax')(out)\n",
        "  return Model(inputs=backbone_cnn.inputs,outputs=out)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2LsXpyc8sgg",
        "outputId": "12ef57bc-165f-4ec4-ab5a-4a2c870c2b46"
      },
      "source": [
        "final_model = multi_veiw_attention(128)\n",
        "final_model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 256, 256, 8)  224         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 256, 256, 8)  32         ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 128, 128, 8)  0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 128, 128, 8)  1608        ['max_pooling2d[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 128, 128, 8)  32         ['conv2d_1[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 8)   0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 64, 64, 16)   3216        ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 64, 64, 16)  64          ['conv2d_2[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 16)  0           ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " simple_attention (simple_atten  (None, 64, 128)     5019848     ['batch_normalization[0][0]']    \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " simple_attention_1 (simple_att  (None, 64, 128)     4233416     ['batch_normalization_1[0][0]']  \n",
            " ention)                                                                                          \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 32, 32, 16)   6416        ['max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " tf.expand_dims (TFOpLambda)    (None, 64, 128, 1)   0           ['simple_attention[0][0]']       \n",
            "                                                                                                  \n",
            " tf.expand_dims_1 (TFOpLambda)  (None, 64, 128, 1)   0           ['simple_attention_1[0][0]']     \n",
            "                                                                                                  \n",
            " simple_attention_2 (simple_att  (None, 64, 128)     4102544     ['batch_normalization_2[0][0]']  \n",
            " ention)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 64, 128, 2)   0           ['tf.expand_dims[0][0]',         \n",
            "                                                                  'tf.expand_dims_1[0][0]']       \n",
            "                                                                                                  \n",
            " tf.expand_dims_2 (TFOpLambda)  (None, 64, 128, 1)   0           ['simple_attention_2[0][0]']     \n",
            "                                                                                                  \n",
            " simple_attention_3 (simple_att  (None, 64, 128)     4004240     ['batch_normalization_3[0][0]']  \n",
            " ention)                                                                                          \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 16)    0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 64, 128, 3)   0           ['concatenate[0][0]',            \n",
            "                                                                  'tf.expand_dims_2[0][0]']       \n",
            "                                                                                                  \n",
            " tf.expand_dims_3 (TFOpLambda)  (None, 64, 128, 1)   0           ['simple_attention_3[0][0]']     \n",
            "                                                                                                  \n",
            " simple_attention_4 (simple_att  (None, 64, 128)     3973520     ['max_pooling2d_3[0][0]']        \n",
            " ention)                                                                                          \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 64, 128, 4)   0           ['concatenate_1[0][0]',          \n",
            "                                                                  'tf.expand_dims_3[0][0]']       \n",
            "                                                                                                  \n",
            " tf.expand_dims_4 (TFOpLambda)  (None, 64, 128, 1)   0           ['simple_attention_4[0][0]']     \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 64, 128, 5)   0           ['concatenate_2[0][0]',          \n",
            "                                                                  'tf.expand_dims_4[0][0]']       \n",
            "                                                                                                  \n",
            " tf.math.reduce_mean (TFOpLambd  (None, 64, 128)     0           ['concatenate_3[0][0]']          \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)            (None, 8192)         0           ['tf.math.reduce_mean[0][0]']    \n",
            "                                                                                                  \n",
            " mlp (mlp)                      (None, 512)          8914432     ['flatten_1[0][0]']              \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 2)            1026        ['mlp[0][0]']                    \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 30,260,682\n",
            "Trainable params: 30,260,586\n",
            "Non-trainable params: 96\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Y2UKGevg1u4",
        "outputId": "aca98bcf-0829-4652-bdcc-edb24deafd85"
      },
      "source": [
        "#GETS TRAIN FILES PATH\n",
        "train_files = []\n",
        "label_files= ['fake','real']\n",
        "for x in os.walk('/content/drive/My Drive/data_fakesecond/train'):\n",
        "    for y in glob.glob(os.path.join(x[0], '*.jpg')):\n",
        "        train_files.append(y)\n",
        "print(len(train_files))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15958\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1G4sB-2LB9Ff",
        "outputId": "e068f05a-51da-4499-a337-8c59135e514d"
      },
      "source": [
        "#GETS VAL FILES PATH\n",
        "val_files = []\n",
        "label_files= ['fake','real']\n",
        "for x in os.walk('/content/drive/My Drive/celeb/test'):\n",
        "    for y in glob.glob(os.path.join(x[0], '*.jpg')):\n",
        "        val_files.append(y)\n",
        "print(len(val_files))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "518\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "To7BiEX_gj2e"
      },
      "source": [
        "import cv2\n",
        "#GETS IMAGE ARRAY OUT GIVEN AN IMAGE PATH\n",
        "def get_input(path):\n",
        "    im = cv2.imread(path)\n",
        "    return(im)\n",
        " \n",
        "#CREATES LABEL VECTORE [0,1] OR [1,0] BY EXPLOITING CLASS TYPE label_files IN FILE PATH \n",
        "def get_output( path, label_files,mode):\n",
        "    if mode =='train':\n",
        "      img_id = path.split('/')[-2]\n",
        "    else:\n",
        "      img_id = path.split('/')[-1].split('_')[0].lower()\n",
        "    laba = []\n",
        "    for label in label_files:\n",
        "      if label == img_id:\n",
        "        laba.append(1)\n",
        "      else:\n",
        "        laba.append(0)\n",
        "    return laba"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLo29vHS-PbO"
      },
      "source": [
        "#GENERATOR FUNCTION TO PASS THE IMAGES AND LABELS TO model.fit FOR TRAINING\n",
        "def image_generator_test(files, label_files,mode, resize=(256,256)):\n",
        " \n",
        "  batch_x = []\n",
        "  batch_y = [] \n",
        "          \n",
        "  for input_path in files:\n",
        "      input = get_input(input_path)\n",
        "      output = get_output(input_path, label_files,mode)\n",
        "      if resize is not None:\n",
        "        input = cv2.resize(input, resize)\n",
        "        #input  = input[np.newaxis,:,:,:]\n",
        "        batch_x.append(input)\n",
        "        batch_y.append(output)\n",
        "   \n",
        "  batch_x = tf.convert_to_tensor(batch_x)\n",
        "  batch_x = tf.cast(batch_x,dtype='float32')\n",
        "  batch_x = tf.keras.applications.xception.preprocess_input(batch_x)\n",
        "  #batch_x = batch_x / 255.0\n",
        "  batch_y = tf.convert_to_tensor(batch_y)\n",
        "  #batch_x = patch_encoder(batch_x)\n",
        "\n",
        "  return batch_x, batch_y\n",
        "\n",
        "imx,imy = image_generator_test(val_files,label_files,'val')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIlKuF7xg44t"
      },
      "source": [
        "#GENERATOR FUNCTION TO PASS THE IMAGES AND LABELS TO model.fit FOR TRAINING\n",
        "def image_generator(files, label_files, batch_size,mode, resize=(256,256)):\n",
        " \n",
        "      while True:\n",
        "          batch_paths  = np.random.choice(a  = files, \n",
        "                                          size = batch_size)\n",
        "          batch_x = []\n",
        "          batch_y = [] \n",
        "          \n",
        "          for input_path in batch_paths:\n",
        "              input = get_input(input_path)\n",
        "              output = get_output(input_path, label_files,mode)\n",
        "              if resize is not None:\n",
        "                input = cv2.resize(input, resize)\n",
        "              #input  = input[np.newaxis,:,:,:]\n",
        "              batch_x.append(input)\n",
        "              batch_y.append(output)\n",
        "   \n",
        "          batch_x = tf.convert_to_tensor(batch_x)\n",
        "          batch_x = tf.cast(batch_x,dtype='float32')\n",
        "          batch_x = tf.keras.applications.xception.preprocess_input(batch_x)\n",
        "          #batch_x = batch_x / 255.0\n",
        "          batch_y = tf.convert_to_tensor(batch_y)\n",
        "          #batch_x = patch_encoder(batch_x)\n",
        "\n",
        "          yield batch_x, batch_y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZHcNGZeuhBiR",
        "outputId": "97759cef-f850-4ba1-ffe5-8f8d90d4c398"
      },
      "source": [
        "final_model.compile('Adam', loss = tf.keras.losses.CategoricalCrossentropy(), metrics = ['accuracy',tf.keras.metrics.AUC()])\n",
        " \n",
        "checkpoint_filepath = '/content/checkpoint5'\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath, save_best_only=True, save_weights_only=True, monitor='val_auc_3', mode='max')\n",
        " \n",
        "history=final_model.fit(image_generator(train_files, label_files,mode='train', batch_size = 16), epochs = 30, steps_per_epoch = 40, validation_data = (imx,imy),validation_batch_size=1, callbacks=[model_checkpoint_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "40/40 [==============================] - 413s 9s/step - loss: 0.8657 - accuracy: 0.5125 - auc_3: 0.5068 - val_loss: 0.6638 - val_accuracy: 0.6506 - val_auc_3: 0.6788\n",
            "Epoch 2/30\n",
            "40/40 [==============================] - 350s 9s/step - loss: 0.7768 - accuracy: 0.5437 - auc_3: 0.5560 - val_loss: 0.7356 - val_accuracy: 0.4614 - val_auc_3: 0.4299\n",
            "Epoch 3/30\n",
            "40/40 [==============================] - 340s 9s/step - loss: 0.8505 - accuracy: 0.5063 - auc_3: 0.5029 - val_loss: 0.7981 - val_accuracy: 0.3378 - val_auc_3: 0.3328\n",
            "Epoch 4/30\n",
            "40/40 [==============================] - 339s 9s/step - loss: 0.7838 - accuracy: 0.5016 - auc_3: 0.5003 - val_loss: 0.6937 - val_accuracy: 0.4884 - val_auc_3: 0.4981\n",
            "Epoch 5/30\n",
            "40/40 [==============================] - 339s 9s/step - loss: 0.7479 - accuracy: 0.4953 - auc_3: 0.5027 - val_loss: 0.6891 - val_accuracy: 0.5656 - val_auc_3: 0.5722\n",
            "Epoch 6/30\n",
            "40/40 [==============================] - 338s 9s/step - loss: 0.7311 - accuracy: 0.4797 - auc_3: 0.4837 - val_loss: 0.6996 - val_accuracy: 0.4865 - val_auc_3: 0.4698\n",
            "Epoch 7/30\n",
            "40/40 [==============================] - 342s 9s/step - loss: 0.7405 - accuracy: 0.4906 - auc_3: 0.4962 - val_loss: 0.6619 - val_accuracy: 0.6564 - val_auc_3: 0.6677\n",
            "Epoch 8/30\n",
            "40/40 [==============================] - 338s 8s/step - loss: 0.7225 - accuracy: 0.4875 - auc_3: 0.4817 - val_loss: 0.7041 - val_accuracy: 0.3958 - val_auc_3: 0.3790\n",
            "Epoch 9/30\n",
            "40/40 [==============================] - 338s 9s/step - loss: 0.7207 - accuracy: 0.4906 - auc_3: 0.4935 - val_loss: 0.7004 - val_accuracy: 0.3320 - val_auc_3: 0.2923\n",
            "Epoch 10/30\n",
            "40/40 [==============================] - 343s 9s/step - loss: 0.7181 - accuracy: 0.4891 - auc_3: 0.5018 - val_loss: 0.6757 - val_accuracy: 0.6660 - val_auc_3: 0.6629\n",
            "Epoch 11/30\n",
            "40/40 [==============================] - 338s 9s/step - loss: 0.7257 - accuracy: 0.5016 - auc_3: 0.5175 - val_loss: 0.7559 - val_accuracy: 0.3436 - val_auc_3: 0.3758\n",
            "Epoch 12/30\n",
            "40/40 [==============================] - 341s 9s/step - loss: 0.7308 - accuracy: 0.4953 - auc_3: 0.4970 - val_loss: 0.7104 - val_accuracy: 0.3436 - val_auc_3: 0.3560\n",
            "Epoch 13/30\n",
            "40/40 [==============================] - 349s 9s/step - loss: 0.7058 - accuracy: 0.4859 - auc_3: 0.4906 - val_loss: 0.7086 - val_accuracy: 0.3436 - val_auc_3: 0.3342\n",
            "Epoch 14/30\n",
            "40/40 [==============================] - 346s 9s/step - loss: 0.7025 - accuracy: 0.5094 - auc_3: 0.5036 - val_loss: 0.7007 - val_accuracy: 0.5521 - val_auc_3: 0.4981\n",
            "Epoch 15/30\n",
            "40/40 [==============================] - 344s 9s/step - loss: 0.7123 - accuracy: 0.4859 - auc_3: 0.4919 - val_loss: 0.7078 - val_accuracy: 0.4093 - val_auc_3: 0.3685\n",
            "Epoch 16/30\n",
            "40/40 [==============================] - 345s 9s/step - loss: 0.7065 - accuracy: 0.5125 - auc_3: 0.5080 - val_loss: 0.6854 - val_accuracy: 0.6564 - val_auc_3: 0.6716\n",
            "Epoch 17/30\n",
            "40/40 [==============================] - 344s 9s/step - loss: 0.6990 - accuracy: 0.5016 - auc_3: 0.5168 - val_loss: 0.6941 - val_accuracy: 0.4768 - val_auc_3: 0.4897\n",
            "Epoch 18/30\n",
            "40/40 [==============================] - 345s 9s/step - loss: 0.7148 - accuracy: 0.4766 - auc_3: 0.4951 - val_loss: 0.6920 - val_accuracy: 0.6236 - val_auc_3: 0.6040\n",
            "Epoch 19/30\n",
            "40/40 [==============================] - 342s 9s/step - loss: 0.7129 - accuracy: 0.4938 - auc_3: 0.4883 - val_loss: 0.7012 - val_accuracy: 0.5019 - val_auc_3: 0.3965\n",
            "Epoch 20/30\n",
            "40/40 [==============================] - 343s 9s/step - loss: 0.7009 - accuracy: 0.5000 - auc_3: 0.5048 - val_loss: 0.7708 - val_accuracy: 0.3417 - val_auc_3: 0.3149\n",
            "Epoch 21/30\n",
            "40/40 [==============================] - 339s 9s/step - loss: 0.7081 - accuracy: 0.5281 - auc_3: 0.5195 - val_loss: 0.7070 - val_accuracy: 0.4363 - val_auc_3: 0.3886\n",
            "Epoch 22/30\n",
            "40/40 [==============================] - 338s 9s/step - loss: 0.7208 - accuracy: 0.5031 - auc_3: 0.5046 - val_loss: 0.6978 - val_accuracy: 0.3514 - val_auc_3: 0.3488\n",
            "Epoch 23/30\n",
            "40/40 [==============================] - 337s 8s/step - loss: 0.7023 - accuracy: 0.5266 - auc_3: 0.5231 - val_loss: 0.6910 - val_accuracy: 0.5695 - val_auc_3: 0.5698\n",
            "Epoch 24/30\n",
            "40/40 [==============================] - 336s 8s/step - loss: 0.7170 - accuracy: 0.4734 - auc_3: 0.4391 - val_loss: 0.6928 - val_accuracy: 0.5985 - val_auc_3: 0.5021\n",
            "Epoch 25/30\n",
            "40/40 [==============================] - 338s 8s/step - loss: 0.7041 - accuracy: 0.4750 - auc_3: 0.4740 - val_loss: 0.6953 - val_accuracy: 0.3591 - val_auc_3: 0.3878\n",
            "Epoch 26/30\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.6991 - accuracy: 0.5219 - auc_3: 0.5264"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-5b125487eab6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel_checkpoint_callback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint_filepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_weights_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_auc_3'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'max'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfinal_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_files\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_checkpoint_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1261\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m               \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1263\u001b[0;31m               _use_cached_eval_dataset=True)\n\u001b[0m\u001b[1;32m   1264\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1535\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1536\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1537\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1538\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    947\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 949\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    950\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3130\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3131\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3133\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1960\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    601\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    604\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bw_ay6t9rthu"
      },
      "source": [
        "imx,imy = image_generator(val_files,label_files,1,'val')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzGvdI4as5mi"
      },
      "source": [
        "final_model = multi_veiw_attention(128)\n",
        "final_model.load_weights('/content/drive/My Drive/saved/multi_veiw_attention.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6qDfpqTrpc8",
        "outputId": "b7a0ec3d-bffc-4f23-f987-e1abaa2993db"
      },
      "source": [
        "final_model.compile('Adam', loss = tf.keras.losses.CategoricalCrossentropy(), metrics = ['accuracy',tf.keras.metrics.AUC()])\n",
        "final_model.evaluate(imx,imy,batch_size=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "518/518 [==============================] - 46s 68ms/step - loss: 0.8341 - accuracy: 0.4749 - auc_1: 0.4720\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8341057300567627, 0.4749034643173218, 0.47204867005348206]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YADG0utXsyt3",
        "outputId": "98dd5dd9-cd1c-4d92-f585-97afadc65e99"
      },
      "source": [
        "temp = multi_veiw_attention(128)\n",
        "temp.load_weights('/content/checkpoint5')\n",
        "drive.mount('/content/gdrive')\n",
        "temp.save('/content/gdrive/My Drive/saved/multi_veiw_attention_mesonet.h5')\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7geeWK4ntg7g"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}